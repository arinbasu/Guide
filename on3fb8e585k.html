<div></div><div>For those of us who are public health professionals, life is data and evidence driven. At the same time, we are living in interesting times in the sense we are drowned in a world of health data that are asking for analyses and generation of insights. Evidence based data analysis, particularly for public health is a necessity. Evidence &amp; causal inference drive public policy and debates. The problem though is, more often than not, the articles and knowledge-base that form the basis of such evidence are rooted in an ancient opaque practice where the readers are not allowed an access to the reproducibility of the process that generated the information in the first place: at times the methods are sparsely described, or the sources are behind paywalls, or not explicit enough.&nbsp;</div><div></div><div>There is a growing demand of reproducible and replicable research designs. What is replicable does not necessarily mean that is reproducible. While the methods of data collection and analyses are made explicit, one does not necessarily share the data and the methods used to generate the insights, or the testing of hypotheses. Reproducible research takes the additional steps of sharing the data and the steps taken to conduct the analyses.&nbsp;</div><div></div><div>Yet this is a stepping stone into the larger more complex world where research gets done not by one person but by a group. Research, particularly in the context of public health, is team sport. The theorist brings together the questions, the epidemiologist brings the data and the methods, the analyst takes the data and crunches the numbers. Together everyone writes. There is a need for transparency at every end and we also owe it to ourselves to make it as easy as possible for our readers to get a glimpse into that world and verify for themselves what we have done. </div><div></div><div>Authorea  is a god-send. This is the only web based authoring system where you can control a live web based writing system seamlessly online, offline, store and forward, including opportunistic availability of going online using a state of the art version control. This is particularly valuable in public health and in computational epidemiology where we need to work as new data becomes available, sometimes in the field, sometimes in the ivory towers, and indeed all sorts of situations. </div><div></div><div>Here is a use case. Think about conducting a continuously updated meta analysis that you can crowd source. Using a continuously updated crowd sourced meta analysis where the codes are free and open to all will avoid the need for re-analysis and revision of the meta analysis when new studies are released. If my code can pick up the new studies soon as they are made available in the data bases I searched, and fed into the methods and streams I set up in the data analyses routine, I can have a continuously updated data analysis system.&nbsp;</div><div></div><div>My intention here is to put a step by step guide on using Authorea and Jupyter notebooks to do reproducible data science in public health that brings in not just dynamically updating a document but doing so seamlessly and brining in the power of a team to provide necessary insights throughout the document&nbsp;<cite class="ltx_cite raw v1">\cite{Peng_2011}</cite>. I will show in the end that you can use this system to read data from WHO (and indeed other repos) and run an analysis for yourself in the time it takes you to read this paper. T</div><div></div><div>In brief,&nbsp; the steps are kind of as follows:</div><div></div><div>Step 1: Start with Authorea and set up an article</div><div>Step 2: Link the article to github or a git repo, do a remote add origin to the github to your local hard drive on a folder after installing git locally</div><div>Step 3:&nbsp; Start a jupyter notebook in the root folder of the git repo and use the python module (python 2 and python 3). You can use R as well; I'd say if you want to use a notebook and want to use R, use an Rnotebook in Rstudio; the effects will be same for the workflow that I outline here. The reason I'd go the python way with an ipynb notebook is that when you share the work and codes, most jupyter notebook servers (such as colaboratory or mybinder.org) use Python 2 or Python 3. So if your reader wants to verify your code and output, you provide him or her the opportunity to do that right away. Else, use something like an r-brain.io to work with julia or R codes to play with. I'd rather use an Rstudio code set for R codes.</div><div>Step 4: Use git to push the ipynb into the Authorea repo; ditto for Rnotebook markdown to push tables, figures, and text generated in the Rnotebook.</div><div></div><div>For this system to work, keep in mind these general principles:</div><div></div><div>Write in markdown; for tables use csv files, and for figures use jpg files</div><div>In Authorea, store the csv files in subfolders in the figures folder&nbsp;</div><div>In Authorea, store the jpeg files in subfolders in the figures folder</div><div>Use the layout.md file to position the various components. </div><div>Learn the config.yml file for figures; there is magic in the  config.yml file worth mastering</div><div>Use bibtex for citation management</div><div></div><div>For everything else, finish in Authorea itself. The html interface in Authorea is as intuitive as it gets, and for plain tables that are not csv, use a separate markdown chunk. The beauty of this system in Authorea is its flexibility (this is as of 2018) where it allows you to blend markdown, html, latex seamlessly. As a result, it does not matter what format you use to write your text. So, here are the step by step approach as to what goes where.</div><div></div><h2 data-label="410256" class="ltx_title_subsection">Step 1: Start with authorea</h2><div></div><div>So we want to build a dynamically updated publication system. By that I mean that the document is so flexible that without repeated upload of figures and tables, once you set a structure or a template, you can practically just do your analyses and write wherever, whenever, yet the "production view" in Authorea reflects that movable analyses and gets updated as you do. This is particularly important for open sourced reproducible research by a group of diverse scholars where readers of the research become your partners.</div><div></div><div>In order to dynamically update the paper, we need to establish that the changing figures, tables and text happens only in some part of the paper so that the structure does not get broken or be repetitive. In any scholarly or information sharing context, as authors and also as readers, we need at the least four elements:</div><div></div><ul><li>Tables of information</li><li>Visualisation of elements</li><li>Attributable arguments or statements with sources (citations); no beliefs or opinions.</li><li>For reproducible research you need to provide source codes of your analyses (here we have used python but you can use R or Julia as well). </li></ul><div>Mix Authorea with dynamically developed graphs and tables to work. You can do all of these in the Authorea main interface by uploading from your local hard drive but you may also want to work on the web on the fly and here github is your friend. You will next need to do a couple of things:</div><div></div><h2 data-label="949138" class="ltx_title_subsection">Tables, figures, bibliography and layout</h2><div></div><div>For each of your figure and table you will need to create two files: a config.yml file and a caption.html file. The caption file will contain caption and the config.yml file will be different for figures and tables. The table with csv data will contain the ipynb file and the figure will contain the config.yml file and the caption.html file. The caption.html file will only contain the title for the figure or the table. The config.yml file is more involved and will contain the following set of codes:</div><div></div><div></div>